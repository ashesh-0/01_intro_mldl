{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e36ce0e",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning and Deep Learning\n",
    "\n",
    "### Acknowledgements\n",
    "\n",
    "The content of this notebook was originally created by Nils Eckstein, Julia Buhmann, and Jan Funke for the 2021 DL@MBL course in Woods Hole, and later chopped up and modified by Florian Jug, Igor Zubarev and Ashesh for the 2023 course DL4MIA.\n",
    "\n",
    "Some code cells will be marked with\n",
    "\n",
    "########################################################################### <br>\n",
    "#######                      START OF YOUR CODE                     ####### <br>\n",
    "########################################################################### <br>\n",
    "\n",
    "... <br>\n",
    "\n",
    "########################################################################### <br>\n",
    "#######                       END OF YOUR CODE                      ####### <br>\n",
    "########################################################################### <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2135319",
   "metadata": {},
   "source": [
    "# Use PyTorch to Train a (Small) Neural Network\n",
    "\n",
    "The previous task demonstrated that chosing the weights of a neural network by hand can be quite painful even for simple functions. This will certainly get out of hand once we have more complex networks with several layers and many neurons per layer. But more importantly, the reason why we want to use neural networks to approximate a function is that (in general) we do not know exactly what the function is. We only have data points that describe the function implicitly.\n",
    "\n",
    "In this task, we will design, train, and evaluate a neural network that can classify points of two different classes on a 2D plane, i.e., the input to our network are the coordinates of points in a plane. Net initial network we want to build should have one hidden layer containing 12 nodes (perceptrons) that receive input from two nodes each, and are themselves connected to one single output node that should predict a binary class for the given input (x,y).\n",
    "\n",
    "For training this network, we will create a training and a testing dataset. We will then create the network and use stochastic gradient descent to train all network parameters on the training dataset and evaluate its performance on the testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e130d87",
   "metadata": {},
   "source": [
    "## Generate Training Data...\n",
    "\n",
    "We create both training and testing dataset from the following function (in practice, we would not know this function but have only the data available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff660ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spiral_data(n_points, noise=1.0):\n",
    "    n = np.sqrt(np.random.rand(n_points,1)) * 780 * (2*np.pi)/360\n",
    "    d1x = -np.cos(n)*n + np.random.rand(n_points,1) * noise\n",
    "    d1y = np.sin(n)*n + np.random.rand(n_points,1) * noise\n",
    "    return (np.vstack((np.hstack((d1x,d1y)),np.hstack((-d1x,-d1y)))), \n",
    "            np.hstack((np.zeros(n_points),np.ones(n_points))))\n",
    "\n",
    "X_train, y_train = generate_spiral_data(100)\n",
    "\n",
    "plt.title('Training set')\n",
    "plt.plot(X_train[y_train==0,0], X_train[y_train==0,1], '.', label='Class 1')\n",
    "plt.plot(X_train[y_train==1,0], X_train[y_train==1,1], '.', label='Class 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "X_test, y_test = generate_spiral_data(1000)\n",
    "\n",
    "plt.title('Test set')\n",
    "plt.plot(X_test[y_test==0,0], X_test[y_test==0,1], '.', label='Class 1')\n",
    "plt.plot(X_test[y_test==1,0], X_test[y_test==1,1], '.', label='Class 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e6be169",
   "metadata": {},
   "source": [
    "### Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bdc8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def accuracy(binary_prediction, target):\n",
    "    \"\"\"Computes the accuracy of a binary prediction vector and a target vector\"\"\"\n",
    "    assert binary_prediction.shape == target.shape, f\"Shapes don't match: {binary_prediction.shape} vs {target.shape}\"\n",
    "    assert isinstance(binary_prediction, torch.Tensor), f\"Expected torch.Tensor, got {type(binary_prediction)}\"\n",
    "    assert isinstance(target, torch.Tensor), f\"Expected torch.Tensor, got {type(target)}\"\n",
    "    x = binary_prediction == target\n",
    "    return x.sum().div(len(x))\n",
    "\n",
    "\n",
    "def get_binary_predictions(model_predictions):\n",
    "   \"\"\"Converts a vector of probabilities to a vector of binary predictions\"\"\"\n",
    "   return torch.round(model_predictions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d75329bf",
   "metadata": {},
   "source": [
    "# Let's create and train the network on the generated data...\n",
    "\n",
    "Try to understand what is roughly going on in the cell below... feel free to use google to figure out what some parts might mean..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# hyper parameters.\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "\n",
    "# data\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train[:,None])) # create your dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "\n",
    "def train(model, optimizer, num_epochs):    \n",
    "  train_losses = []\n",
    "  train_accuracies = []\n",
    "  for epoch in tqdm(range(num_epochs)):\n",
    "    output = train_one_epoch(model, optimizer)\n",
    "    train_losses.append(output['loss'])\n",
    "    train_accuracies.append(output['accuracy'])\n",
    "  return {'loss':train_losses, 'accuracy':train_accuracies}\n",
    "\n",
    "     \n",
    "\n",
    "def train_one_epoch(model, optimizer):\n",
    "  model.train()\n",
    "  loss_arr = []\n",
    "  accuracy_arr = []\n",
    "  for data, target in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = nn.MSELoss()(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    binary_preds = get_binary_predictions(output)\n",
    "    accuracy_arr.append(accuracy(binary_preds, target))\n",
    "    loss_arr.append(loss.item())\n",
    "\n",
    "  return {'output':output, 'loss':np.mean(loss_arr), 'accuracy':np.mean(accuracy_arr)}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lets create the model \n",
    "simple_model  = nn.Sequential(\n",
    "    nn.Linear(2, 12),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(12,1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "# visualize the model\n",
    "print(simple_model)\n",
    "\n",
    "# Lets create the optimizer\n",
    "simple_optimizer = optim.SGD(simple_model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "# Train the model\n",
    "train_stats = train(simple_model, simple_optimizer, 100)\n",
    "\n",
    "# Predict on the testing data\n",
    "model_output = simple_model(torch.Tensor(X_test))\n",
    "prediction = get_binary_predictions(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f2ceb2",
   "metadata": {},
   "source": [
    "Now that training is done, let's plot the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b786bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(pred, model_name):\n",
    "    plt.subplot(1,2,1)\n",
    "\n",
    "    plt.title('Test set')\n",
    "    plt.plot(X_test[y_test==0,0], X_test[y_test==0,1], '.')\n",
    "    plt.plot(X_test[y_test==1,0], X_test[y_test==1,1], '.')\n",
    "    plt.subplot(1,2,2)\n",
    "\n",
    "    plt.title(f'{model_name}_model classification')\n",
    "    plt.plot(X_test[pred==0,0], X_test[pred==0,1], '.')\n",
    "    plt.plot(X_test[pred==1,0], X_test[pred==1,1], '.')\n",
    "    plt.show()\n",
    "\n",
    "plot_results(prediction[:,0], 'simple_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cc3dd1",
   "metadata": {},
   "source": [
    "And the result is... **BAD!**\n",
    "\n",
    "This is, because the network is likely not powerful enough... hence, the model we used is not adequate for the training task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a8468",
   "metadata": {},
   "source": [
    "## Exercise: find a better solution...\n",
    "\n",
    "Create a second network that is somehow different and performs the task better...\n",
    "\n",
    "**Hint**: Likely it is a good idea to copy the cell from above and somehow change it in a meaningful way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d281a411",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "#######                      START OF YOUR CODE                     #######\n",
    "###########################################################################\n",
    "\n",
    "# create an alternative model (network) here.\n",
    "# Take the code of simple_model as a starting point and modify it.\n",
    "\n",
    "good_model = ...\n",
    "\n",
    "###########################################################################\n",
    "#######                       END OF YOUR CODE                      #######\n",
    "###########################################################################\n",
    "\n",
    "# Visualize the architecture \n",
    "print(good_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba95508",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Write the configuration and training code in the following cell.\n",
    "\n",
    "**Hint**: You'd need to configure model for training with compile function, provide training data and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model for training\n",
    "###########################################################################\n",
    "#######                      START OF YOUR CODE                     #######\n",
    "###########################################################################\n",
    "\n",
    "# Hint: You can use the same optimizer as before, but you might want to change it to something else, like Adam ;) \n",
    "good_optimizer = ...\n",
    "\n",
    "\n",
    "#Hint: And train the newly created model using train() function with correct optimizer and number of epochs\n",
    "#Hint: Try to change the number of epochs to something else than 100 and see how it affects the results. Should it be bigger or smaller in this case?\n",
    "train_stats = ...\n",
    "###########################################################################\n",
    "#######                       END OF YOUR CODE                      #######\n",
    "###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1811850",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.round((good_model(torch.Tensor(X_test))).detach().numpy())\n",
    "plot_results(prediction[:,0], 'good_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34fc97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training metrics\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_stats['loss'])\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_stats['accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354957f9",
   "metadata": {},
   "source": [
    "### Done? Cooool!\n",
    "\n",
    "You should now make a short coding break and visit the website https://playground.tensorflow.org\n",
    "\n",
    "Play a bit with it... figure out what elements are part of a typical network training workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:38:11) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "afc28755679c774118b3b3af99e405c53d143b6e5ce38cf7ce1e143223a5e16a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

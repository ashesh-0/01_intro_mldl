{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb77672",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning and Deep Learning\n",
    "\n",
    "### Acknowledgements\n",
    "\n",
    "The content of this notebook was originally created by Nils Eckstein, Julia Buhmann, and Jan Funke for the 2021 DL@MBL course in Woods Hole, and later chopped up and modified by Florian Jug for the 2021 course DL4MIA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3fdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443a7103",
   "metadata": {},
   "source": [
    "### Let's get the MNIST data...\n",
    "\n",
    "This is one of the most famous and most frequently used datasets of small images of hand-written digits and their corresponding ground-truth classes.\n",
    "\n",
    "In this exercise we will learn to predict the correct class given an image of a hand-written digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b50be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\"\"\"\n",
    "Returns:\n",
    "2 tuples:\n",
    "\n",
    "x_train, x_test: uint8 array of grayscale image data with shape (num_samples, 28, 28).\n",
    "y_train, y_test: uint8 array of digit labels (integers in range 0-9) with shape (num_samples,).\n",
    "\"\"\"\n",
    "\n",
    "# Show example data\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(x_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(x_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(x_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(x_train[3], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f165cd6",
   "metadata": {},
   "source": [
    "### Let's create a network we'd like to train...\n",
    "\n",
    "The one currently implemented in the cell below will turn out to not work so well. Run it anyways, but then come back here and start playing with changing the network architecture and hopefully find a better working model for the task at hand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (x_train.shape[1], x_train.shape[2], 1)\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(filters=1,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Conv2D(filters=2,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dense(10, activation='softmax')) # softmax for classification\n",
    "\n",
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adagrad', # adaptive optimizer (still similar to SGD)\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7641fda5",
   "metadata": {},
   "source": [
    "### Brind data in the shape we need during training...\n",
    "\n",
    "In particular, this cell performs the following:\n",
    " * add a channel dimension to train and test data\n",
    " * normalize the pixel intensities to [0,1]\n",
    " * transform the ground-truth label from a digit (0, ..., 9) to one-hot encoded vectors. (Example: the one-hot encoded vector for digit `3` will become `0001000000`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85474b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# add a channel dimension to the images\n",
    "x_train = x_train.reshape(x_train.shape[0],\n",
    "                          x_train.shape[1],\n",
    "                          x_train.shape[2],\n",
    "                          1)\n",
    "x_test = x_test.reshape(x_test.shape[0],\n",
    "                        x_test.shape[1],\n",
    "                        x_test.shape[2],\n",
    "                        1)\n",
    "\n",
    "# rescale intensities to be between 0 and 1\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert the labels into one-hot encodings\n",
    "y_train_onehot = to_categorical(y_train, 10)\n",
    "y_test_onehot = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3967df6f",
   "metadata": {},
   "source": [
    "### Train the network...\n",
    "\n",
    "Note that we decided on some things like the number of epochs, or a batch_size... what is all this? Could we have chosen other values? What would change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.fit(x_train,\n",
    "             y_train_onehot,\n",
    "             steps_per_epoch=1000,\n",
    "             batch_size=16,\n",
    "             epochs=3,\n",
    "             verbose=1,\n",
    "             validation_data=(x_test, y_test_onehot)) # never actually validate using test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7339802",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cnn_model.evaluate(x_test, y_test_onehot, verbose=0)\n",
    "print('MNIST test set accuracy:', score[1])\n",
    "\n",
    "# visualize some test data and network output\n",
    "y_predict = cnn_model.predict(x_test, verbose=0)\n",
    "y_predict_digits = [np.argmax(y_predict[i]) for i in range(y_predict.shape[0])]\n",
    "\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(x_test[0,:,:,0], cmap=plt.get_cmap('gray'))\n",
    "plt.title(\"Pred.: %d\"%y_predict_digits[0])\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(x_test[1,:,:,0], cmap=plt.get_cmap('gray'))\n",
    "plt.title(\"Pred.: %d\"%y_predict_digits[1])\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(x_test[2,:,:,0], cmap=plt.get_cmap('gray'))\n",
    "plt.title(\"Pred.: %d\"%y_predict_digits[2])\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(x_test[3,:,:,0], cmap=plt.get_cmap('gray'))\n",
    "plt.title(\"Pred.: %d\"%y_predict_digits[3])\n",
    "\n",
    "print(\"CNN predictions: {0}, {1}, {2}, {3}\".format(y_predict_digits[0],\n",
    "                                                   y_predict_digits[1],\n",
    "                                                   y_predict_digits[2],\n",
    "                                                   y_predict_digits[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a5570b",
   "metadata": {},
   "source": [
    "### Show a few more examples, so we also see some of the errors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4419fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 8, figsize=(20,15))\n",
    "errors=0\n",
    "for i in range(40):\n",
    "    if y_predict_digits[i]==y_test[i]:\n",
    "        axes.flatten()[i].imshow(x_test[i,:,:,0], cmap=plt.get_cmap('gray'))\n",
    "        axes.flatten()[i].set_title('ok')\n",
    "    else:\n",
    "        axes.flatten()[i].imshow(x_test[i,:,:,0], cmap=plt.get_cmap('Reds'))\n",
    "        axes.flatten()[i].set_title('PREDICTION: %s'%(y_predict_digits[i]))\n",
    "        errors+=1\n",
    "        \n",
    "print(\"Errors: %d\"%errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f0e8c",
   "metadata": {},
   "source": [
    "### NEXT: improve the network, maybe also the network training, and reduce the test errors...\n",
    "\n",
    "Another fun exercise might be to try to find the smallest network (fewest trainable parameters) that still leads to an test error smaller 15%...\n",
    "\n",
    "**Note:** You will find out that if you modify the network, TensorFlow might hick up... likely you want to restart the kernel every time you make changes to the network..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cf3a0a",
   "metadata": {},
   "source": [
    "### Once you're done, please anser these question:\n",
    "\n",
    " * What did you play with, what made the biggest difference?\n",
    " * How many parameters did you end up unsing?\n",
    " * How long did you train the network?\n",
    " * What was the best test-error you got overall?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:01_intro_mldl]",
   "language": "python",
   "name": "conda-env-01_intro_mldl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

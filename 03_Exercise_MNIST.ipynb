{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb77672",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning and Deep Learning\n",
    "\n",
    "### Acknowledgements\n",
    "\n",
    "The content of this notebook was originally created by Nils Eckstein, Julia Buhmann, and Jan Funke for the 2021 DL@MBL course in Woods Hole, and later chopped up and modified by Florian Jug and Igor Zubarev for the 2022 course DL4MIA.\n",
    "\n",
    "Some code cells will be marked with\n",
    "\n",
    "########################################################################### <br>\n",
    "#######                     FIND WAYS TO IMPROVE                    ####### <br>\n",
    "########################################################################### <br>\n",
    "\n",
    "or \n",
    "\n",
    "########################################################################### <br>\n",
    "#######                      START OF YOUR CODE                     ####### <br>\n",
    "########################################################################### <br>\n",
    "\n",
    "... <br>\n",
    "\n",
    "########################################################################### <br>\n",
    "#######                       END OF YOUR CODE                      ####### <br>\n",
    "########################################################################### <br>\n",
    "\n",
    "This indicates that you need to find a possible errors in the code or in the function parameters. Or add some code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443a7103",
   "metadata": {},
   "source": [
    "### Let's get the MNIST data...\n",
    "\n",
    "This is one of the most famous and most frequently used datasets of small images of hand-written digits and their corresponding ground-truth classes.\n",
    "\n",
    "In this exercise we will learn to predict the correct class given an image of a hand-written digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae04d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashesh.ashesh/miniconda3/envs/Disentangle/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data  60000\n",
      "Test data  10000\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets as dts\n",
    "import torchvision\n",
    "transforms = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])\n",
    "trainset=dts.MNIST(root='./data',train=True,download=True,\n",
    "                   transform=transforms)\n",
    "\n",
    "\n",
    "print('Train data ', len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd608c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, tar = trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3a33d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afdae97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b50be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell should also be run for the super bonus exercise \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Show example data\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(trainset[0][0][0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(trainset[1][0][0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(trainset[2][0][0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(trainset[3][0][0], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7641fda5",
   "metadata": {},
   "source": [
    "### Brind data in the shape we need during training...\n",
    "\n",
    "In particular, this cell performs the following:\n",
    " * add a channel dimension to train and test data\n",
    " * normalize the pixel intensities to [0,1]\n",
    " * transform the ground-truth label from a digit (0, ..., 9) to one-hot encoded vectors. (Example: the one-hot encoded vector for digit `3` will become `0001000000`, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f165cd6",
   "metadata": {},
   "source": [
    "### Let's create a network we'd like to train...\n",
    "\n",
    "The one currently implemented in the cell below will turn out to not work so well. Run it anyways, but then come back here and start playing with changing the network architecture and hopefully find a better working model for the task at hand!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a5570b",
   "metadata": {},
   "source": [
    "### Show a few more examples, so we also see some of the errors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4419fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(5, 8, figsize=(20,15))\n",
    "# errors=0\n",
    "# for i in range(40):\n",
    "#     if y_predict_digits[i]==y_test[i]:\n",
    "#         axes.flatten()[i].imshow(x_test[i,:,:,0], cmap=plt.get_cmap('gray'))\n",
    "#         axes.flatten()[i].set_title('ok')\n",
    "#     else:\n",
    "#         axes.flatten()[i].imshow(x_test[i,:,:,0], cmap=plt.get_cmap('Reds'))\n",
    "#         axes.flatten()[i].set_title('PREDICTION: %s'%(y_predict_digits[i]))\n",
    "#         errors+=1\n",
    "        \n",
    "# print(\"Errors: %d\"%errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7aa81cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:  False\n",
      "PyTorch version:  1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Test if GPU is available in torch. We may need to run this part on CPU because of hardware incompability\n",
    "import torch \n",
    "print('CUDA available: ', torch.cuda.is_available())\n",
    "print('PyTorch version: ', torch.__version__)\n",
    "\n",
    "# Assign correct device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fffea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# from torchsummary import summary\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "epochs = 3\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Let's convert numpy arrays to torch tensors and create a Dataset object. \n",
    "# Note, that we don't need to convert to one-hot, but we need to change the order of dimensions \n",
    "# to comply with torch convention [batch_size, channels, H, W]\n",
    "# tensor.permute is applied on a tensor and inputs new order of dimesions\n",
    "\n",
    "# Create a dataset object\n",
    "train_dataset = trainset \n",
    "\n",
    "# Define an iterable dataloader which allows batching\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define a loss function \n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Now let's define a model. PyTorch models and layers inherit from torch.nn.Module\n",
    "class MNIST_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Classifier, self).__init__()\n",
    "        \n",
    "        # Hint: You need to correct the number of channels in convolutional layers as you did with TensoFlow model above\n",
    "        # Note that you need to set input and output channels separately. \n",
    "        # You can also look at the output shapes in the torchsummary\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 3))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        # Hint: Note that you need to set input and output channels separately and consecutive layers \n",
    "        # should have the same number of filters\n",
    "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3))\n",
    "        self.fc1 = nn.Linear(in_features=800, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Layers are essentially functions. So here we sequantially apply those to the input. \n",
    "        # You can also use print(x.size()) after any step for debug\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # View operation reshapes tensor with -1 meaning all the remaining values will go to that dimension\n",
    "        x = x.view(-1, 32 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create model instance and move it to GPU\n",
    "model = MNIST_Classifier()\n",
    "model.to(device)\n",
    "\n",
    "# Finally let's define an optimizer. Note that we need to provide parameters, \n",
    "# which will be optimized(in our case, all model parameters) and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Visualize the model. PyTorch doesn't have an in-built model summary. \n",
    "# It's available via a separate torchsummary package. We provide the model itself and the shape of the input tensor\n",
    "# summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f37f92",
   "metadata": {},
   "source": [
    "### Define a training loop and train the network...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c499047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- epoch 0 -----\n",
      "Loss: 0.30947034655343386\n",
      "Accuracy: 90.69163113006397\n",
      "\n",
      "----- epoch 1 -----\n",
      "Loss: 0.09760098474006901\n",
      "Accuracy: 96.89332356076758\n",
      "\n",
      "----- epoch 2 -----\n",
      "Loss: 0.07369708971367148\n",
      "Accuracy: 97.57462686567165\n"
     ]
    }
   ],
   "source": [
    "# Iterate over number of epochs\n",
    "for epoch in range(epochs):\n",
    "    train_loss_results = 0\n",
    "    train_accuracy_results = 0\n",
    "    \n",
    "    # Set model to train/eval mode is important for some layers(e.g. Dropout) to behave correctly\n",
    "    model.train()\n",
    "    print(f'\\n----- epoch {epoch} -----')\n",
    "    \n",
    "    # Iterate over the dataloader. Each iteration produces one batch of shape [batch_size, channels, H, W]\n",
    "    for data in train_dataloader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move images and labels to correct device. This operation is only required for gpu training\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Set the gradients of all tensors to zero \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute forward pass(calling forward method of a model) for current batch\n",
    "        predictions = model(inputs)\n",
    "        \n",
    "        # Calculate the loss value \n",
    "        loss = loss_func(predictions, labels.long())\n",
    "        \n",
    "        # Compute the gradient of the loss function w.r.t every model parameter, that has requires_grad=True\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters using the gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss values. We only store the number by calling .item()\n",
    "        train_loss_results += loss.item()\n",
    "        \n",
    "        # Accumulate accuracy by first taking the index of largest logit, \n",
    "        # comparing it with the ground truth labels and summing accross batch\n",
    "        train_accuracy_results += ((predictions.argmax(dim=1) == labels).sum().item())\n",
    "\n",
    "    print(f'Loss: {train_loss_results / len(train_dataloader)}')\n",
    "    print(f'Accuracy: {100 * train_accuracy_results / (batch_size * len(train_dataloader))}')\n",
    "                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6af1921",
   "metadata": {},
   "source": [
    "## Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a test dataset and dataloader\n",
    "test_dataset =dts.MNIST(root='./data',train=False,download=True,\n",
    "                   transform=transforms)\n",
    "\n",
    "print('Test data ', len(test_dataset))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5c73326",
   "metadata": {},
   "source": [
    "### Let's see how well we did qualitatively..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ccd919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example data\n",
    "def get_prediction(inp):\n",
    "    inp = inp.to(device)\n",
    "    pred_tmp = model(inp.unsqueeze(0))\n",
    "    pred_tmp = pred_tmp.argmax(dim=1).item()\n",
    "    return pred_tmp\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "inp_tmp, tar_tmp = test_dataset[0]\n",
    "pred_tmp = get_prediction(inp_tmp)\n",
    "ax = plt.imshow(inp_tmp[0], cmap=plt.get_cmap('gray'))\n",
    "plt.gca().set_title(f'Pred:{pred_tmp}, GT:{tar_tmp}')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "inp_tmp, tar_tmp = test_dataset[4]\n",
    "pred_tmp = get_prediction(inp_tmp)\n",
    "ax = plt.imshow(inp_tmp[0], cmap=plt.get_cmap('gray'))\n",
    "plt.gca().set_title(f'Pred:{pred_tmp}, GT:{tar_tmp}')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "inp_tmp, tar_tmp = test_dataset[12]\n",
    "pred_tmp = get_prediction(inp_tmp)\n",
    "ax = plt.imshow(inp_tmp[0], cmap=plt.get_cmap('gray'))\n",
    "plt.gca().set_title(f'Pred:{pred_tmp}, GT:{tar_tmp}')\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "inp_tmp, tar_tmp = test_dataset[21]\n",
    "pred_tmp = get_prediction(inp_tmp)\n",
    "ax = plt.imshow(inp_tmp[0], cmap=plt.get_cmap('gray'))\n",
    "plt.gca().set_title(f'Pred:{pred_tmp}, GT:{tar_tmp}')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7913f1e9",
   "metadata": {},
   "source": [
    "### Bonus exercise! Implement validation loop in PyTorch\n",
    "\n",
    "Usually, validation is done inside the training loop\n",
    "\n",
    "***Hint:*** Almost all the steps are analogous to the training loop, and there's no gradient calculation! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8ac9c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data  10000\n",
      "Loss: 0.07993623416516396\n",
      "Accuracy: 96.89490445859873\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "#######                   START OF YOUR CODE                        #######\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "# Define an iterable dataloader which allows batching\n",
    "# Hint: Look for how train_dataloader was created above.\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size) #...\n",
    "\n",
    "test_loss_results = 0\n",
    "test_accuracy_results = 0 \n",
    "    \n",
    "# This context manager is needed to disable gradient calculation for  \n",
    "with torch.no_grad():\n",
    "    for test_data in test_dataloader: #...\n",
    "        test_inputs, test_labels = test_data\n",
    "        test_inputs = test_inputs.to(device)\n",
    "        test_labels = test_labels.to(device)\n",
    "\n",
    "        # Compute forward pass\n",
    "        test_predictions = model(test_inputs)#....\n",
    "\n",
    "        # Calculate loss value\n",
    "        test_loss = loss_func(test_predictions, test_labels.long())#....\n",
    "\n",
    "        test_loss_results += test_loss.item() #....\n",
    "        test_accuracy_results += ((test_predictions.argmax(dim=1) == test_labels).sum().item()) #....\n",
    "\n",
    "    print(f'Loss: {test_loss_results / len(test_dataloader)}')\n",
    "    print(f'Accuracy: {100 * test_accuracy_results / (batch_size * len(test_dataloader))}')\n",
    "        \n",
    "\n",
    "###########################################################################\n",
    "#######                    END OF YOUR CODE                         #######\n",
    "###########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cf3a0a",
   "metadata": {},
   "source": [
    "### Once you're done, please answer these question:\n",
    "\n",
    " * What did you play with, what made the biggest difference?\n",
    " * How many parameters did you end up unsing?\n",
    " * How long did you train the network?\n",
    " * What was the best test-error you got overall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ad72d",
   "metadata": {},
   "source": [
    "### Congratulations! You've made it to the end "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "afc28755679c774118b3b3af99e405c53d143b6e5ce38cf7ce1e143223a5e16a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
